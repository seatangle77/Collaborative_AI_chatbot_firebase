import os
from dotenv import load_dotenv
import google.generativeai as genai
import json
from app.preprocessor_anomaly import (
    build_cognitive_anomaly_input,
    build_behavior_anomaly_input,
    build_attention_anomaly_input
)
import concurrent.futures

# âœ… åŠ è½½ .env
load_dotenv()

# âœ… è®¾ç½®ç¯å¢ƒå˜é‡ä¾› SDK ä½¿ç”¨
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

def analyze_all_anomalies(chunk_data: dict) -> dict:
    model = genai.GenerativeModel("gemini-2.5-pro-preview-06-05")

    cognitive_input = build_cognitive_anomaly_input(chunk_data)
    behavior_input = build_behavior_anomaly_input(chunk_data)
    attention_input = build_attention_anomaly_input(chunk_data)

    prompt_text = f"""
ä½ æ˜¯ä¸€ä¸ªå¤šç»´åº¦å°ç»„åˆ†æä¸“å®¶ï¼Œè´Ÿè´£è¯†åˆ«åä½œè¿‡ç¨‹ä¸­çš„ä¸‰ç±»å¼‚å¸¸ï¼šè®¤çŸ¥åå·®ã€è¡Œä¸ºå¼‚å¸¸ã€æ³¨æ„åŠ›åç§»ã€‚

å¼‚å¸¸å‚è€ƒç±»å‹å¦‚ä¸‹ï¼ˆä¾›ä½ å‚è€ƒå¹¶è¿›è¡Œåˆ¤æ–­ï¼‰ï¼š

[
  {{
    "type": "è¡Œä¸ºç¼ºå¤±",
    "status": "æœ¬è½®è¡Œä¸ºå‚ä¸åº¦åä½",
    "evidence": "æœªå‘è¨€ï¼ŒNotionç¼–è¾‘è®°å½•ä¸ºç©ºï¼Œæ— æµè§ˆä»»åŠ¡é¡µé¢",
    "suggestion": "å°è¯•åˆ†äº«ä½ æŸ¥åˆ°çš„å†…å®¹ï¼Œæˆ–æå‡ºä¸€ä¸ªé—®é¢˜å¼•å‘è®¨è®ºã€‚"
  }},
  {{
    "type": "è¡Œä¸ºåç¦»",
    "status": "è¡Œä¸ºå…³æ³¨åç¦»ä»»åŠ¡",
    "evidence": "é¡µé¢åœç•™è¿‡ä¹…ã€é¢‘ç¹è·³é¡µæˆ–èšç„¦æ— å…³å†…å®¹",
    "suggestion": "å›åˆ°ä¸ä½ å½“å‰ä»»åŠ¡ç›¸å…³çš„é¡µé¢ï¼Œå…³æ³¨å°ç»„å½“å‰ä¸»é¢˜ã€‚"
  }},
  {{
    "type": "å†…å®¹é‡å¤",
    "status": "è®¤çŸ¥å‚ä¸åº¦è¾ƒä½",
    "evidence": "æ–‡æœ¬é‡å¤ç‡é«˜ï¼Œç›¸ä¼¼å¥å¼å æ¯”è¾ƒé«˜",
    "suggestion": "å°è¯•æ¢ä¸€ä¸ªè§’åº¦å‘è¨€ï¼Œæˆ–å¯¹æ¯”ä»–äººè§‚ç‚¹åè¡¥å……æ€è€ƒã€‚"
  }},
  {{
    "type": "æ— å›åº”",
    "status": "ç¼ºä¹å›åº”è¡Œä¸º",
    "evidence": "æ— å¼•ç”¨ã€æ— æé—®ã€æ— æ¥ç»­å‘è¨€è¡Œä¸º",
    "suggestion": "ä¸»åŠ¨å¯¹ä»–äººè§‚ç‚¹åšå‡ºå›åº”ï¼Œä¿ƒè¿›æ›´æ·±å…¥çš„å¯¹è¯ã€‚"
  }},
  {{
    "type": "ä»»åŠ¡åç§»",
    "status": "ä½ çš„æ³¨æ„åŠ›ä¸å°ç»„æ–¹å‘ä¸ä¸€è‡´",
    "evidence": "ç»„å†…é¡µé¢çƒ­åº¦å›¾ + å½“å‰æµè§ˆè®°å½•ä¸ä¸€è‡´",
    "suggestion": "æŸ¥çœ‹ç»„å‘˜æ­£åœ¨å…³æ³¨çš„å†…å®¹ï¼Œå¯»æ‰¾å…±åŒåˆ‡å…¥ç‚¹ã€‚"
  }},
  {{
    "type": "åˆ†å¸ƒåˆ†æ•£",
    "status": "å›¢é˜Ÿå…³æ³¨è¿‡äºåˆ†æ•£",
    "evidence": "æ— æ˜æ˜¾å…±é¡µè®¿é—®ï¼Œé¡µé¢çƒ­åº¦å‡åŒ€",
    "suggestion": "æ˜¯å¦éœ€è¦é€‰å‡ºç„¦ç‚¹è¯é¢˜æˆ–å…±åŒæœç´¢è·¯å¾„ï¼Ÿ"
  }}
]

è®¤çŸ¥æ•°æ®ï¼š{json.dumps(cognitive_input, ensure_ascii=False, indent=2)}

è¡Œä¸ºæ•°æ®ï¼š{json.dumps(behavior_input, ensure_ascii=False, indent=2)}

æ³¨æ„åŠ›æ•°æ®ï¼š{json.dumps(attention_input, ensure_ascii=False, indent=2)}

è¯·ä»ä¸Šè¿°æ•°æ®ä¸­åˆ¤æ–­æœ€å¯èƒ½çš„å¼‚å¸¸ç±»å‹ï¼Œå¹¶è¾“å‡ºç®€æ´æ‘˜è¦å’Œè¯¦ç»†å»ºè®®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

{{
  "summary": "ä½ å½“å‰æµè§ˆå†…å®¹ä¸å°ç»„æ–¹å‘ç•¥æœ‰åç§»ï¼Œå¯èšç„¦å½“å‰è®¨è®ºä¸»é¢˜ã€‚",
  "detail": {{
    "type": "ä»»åŠ¡åç§»",
    "status": "ä½ çš„æ³¨æ„åŠ›ä¸å°ç»„æ–¹å‘ä¸ä¸€è‡´",
    "evidence": "ç»„å†…é¡µé¢çƒ­åº¦å›¾ + å½“å‰æµè§ˆè®°å½•ä¸ä¸€è‡´",
    "suggestion": "æŸ¥çœ‹ç»„å‘˜æ­£åœ¨å…³æ³¨çš„å†…å®¹ï¼Œå¯»æ‰¾å…±åŒåˆ‡å…¥ç‚¹ã€‚"
  }}
}}
"""

    print("ğŸš€ å¼€å§‹è°ƒç”¨ [Anomaly AI ç»¼åˆåˆ†æ] ...")
    response = model.generate_content(
        contents=[{"role": "user", "parts": [{"text": prompt_text}]}],
        generation_config=genai.types.GenerationConfig(temperature=0.7)
    )
    print("âœ… [Anomaly AI] è¿”å›ç»“æœï¼š", response.text)

    return {"raw_response": response.text}