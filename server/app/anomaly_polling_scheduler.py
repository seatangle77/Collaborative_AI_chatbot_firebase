import queue
import threading
import time
import traceback
from datetime import datetime, timezone

from server.app.anomaly_analyze import ai_analyze_anomaly_status, local_analyze
from server.app.anomaly_preprocessor import parse_iso_time
from server.app.logger.logger_loader import logger

_group_id = None
_users_info = None
# 120ç§’çš„é—´éš”
_default_interval_seconds = 120

# æ˜¯å¦åœæ­¢åˆ†æ
_stop_analyze = True

# æ‰§è¡Œåˆ†æä»»åŠ¡çš„çº¿ç¨‹
_analyze_thread = None
_ai_analyze_thread = None

_ai_analyze_q = queue.Queue(1000)

# å¯åŠ¨æ—¶é—´å’Œå¼€å§‹åˆ†ææ—¶é—´ï¼Œç”¨äºåˆ†æå†å²æ•°æ®ï¼Œå¦‚æœ_analyze_start_timeè®¾ç½®æˆå½“å‰æ—¶é—´åˆ™ä»å½“å‰æ—¶é—´å¼€å§‹åˆ†æ
_boot_time = datetime.now(timezone.utc)
_analyze_start_time = datetime.now(timezone.utc)

# _group_id = "cc8f1d29-7a49-4975-95dc-7ac94aefc04b"
# _stop_analyze = False
# _analyze_start_time = parse_iso_time("2025-07-10T07:02:27")
def get_analyze_start_time() -> datetime:
    return _analyze_start_time + (datetime.now(timezone.utc) - _boot_time)

def clear_cache():
    global _group_id, _users_info, _ai_analyze_q, _ai_analyze_result_histor
    _group_id = None
    _users_info = None
    _ai_analyze_q = queue.Queue(1000)


def start_analyze(group_id: str):
    clear_cache()

    global _group_id,_stop_analyze
    _stop_analyze = False
    _group_id = group_id

def stop_analyze(group_id: str):
    global _stop_analyze
    _stop_analyze = True

    clear_cache()

def analyze_handler():
    logger.info("ğŸ”„ [å¼‚å¸¸åˆ†æè½®è¯¢] å¯åŠ¨åˆ†æè½®è¯¢çº¿ç¨‹...")
    global _group_id, _stop_analyze, _ai_analyze_q

    # 120ç§’çš„åˆ†æé—´éš”
    interval_seconds = 120
    last_analyze_time = None
    while True:
        try:
            if _stop_analyze:
                time.sleep(1)
                continue

            if _group_id is None:
                time.sleep(1)
                logger.error("âŒ [å¼‚å¸¸åˆ†æè½®è¯¢] group_idæœªè®¾ç½®ï¼Œæ— æ³•æ‰§è¡Œåˆ†æã€‚")
                continue


            if last_analyze_time is None:
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œç­‰å¾…interval_secondså†å¼€å§‹
                last_analyze_time = get_analyze_start_time()
                time.sleep(interval_seconds)
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…ã€‚interval_secondsæ‰§è¡Œä¸€æ¬¡åˆ†æï¼Œä¸è¶³æ—¶é—´éœ€è¦ç­‰å¾…
                elapsed = get_analyze_start_time() - last_analyze_time
                if elapsed.total_seconds() < interval_seconds:
                    time.sleep(interval_seconds - elapsed.total_seconds())

            current_time = get_analyze_start_time()

            # æœ¬åœ°æ•°æ®åˆ†æ
            chunk_data_with_local_analyze, local_analyze_result = local_analyze(_group_id, last_analyze_time, current_time)

            # å†™å…¥é˜Ÿåˆ—ï¼Œå¼‚æ­¥å¤„ç†AIåˆ†æ
            if chunk_data_with_local_analyze:
                _ai_analyze_q.put((_group_id, chunk_data_with_local_analyze))

            # å–æœ¬æ¬¡åˆ†æçš„å¼€å§‹æ—¶é—´-å³å–æ•°æˆªæ­¢æ—¶é—´ï¼Œä½œä¸ºä¸‹ä¸€æ¬¡åˆ†æçš„èµ·å§‹æ—¶é—´
            last_analyze_time = current_time
        except Exception:
            logger.error('Error in analyze_handler loop: %s' % traceback.format_exc())


def ai_analyze_handler():
    logger.info("ğŸ”„ [AIå¼‚å¸¸åˆ†æ] å¯åŠ¨åˆ†æè½®è¯¢çº¿ç¨‹...")
    global  _stop_analyze, _ai_analyze_q

    while True:
        try:
            time.sleep(1)
            if _stop_analyze:
                continue

            while not _ai_analyze_q.empty():
                group_id, chunk_data_with_local_analyze = _ai_analyze_q.get()

                # è°ƒç”¨AIåˆ†ææ¥å£
                stage_start = time.time()
                result = None
                try:
                    result = ai_analyze_anomaly_status(group_id, chunk_data_with_local_analyze)
                    if not result:
                        # æ— åˆ†æç»“æœ
                        continue 

                except Exception as e:
                    logger.error(f"âŒ [AIå¼‚å¸¸åˆ†æ] AIåˆ†æå¼‚å¸¸: {traceback.format_exc()}")
                stage2_duration = time.time() - stage_start
                logger.info(f"ğŸ¤– [AIå¼‚å¸¸åˆ†æ] AIåˆ†æå®Œæˆï¼Œè€—æ—¶{stage2_duration:.2f}ç§’ã€‚ç»“æœï¼š", str(result)[:100])

        except Exception:
            logger.error('Error in ai_analyze_handler loop: %s' % traceback.format_exc())


def run_analyze():
    global _analyze_thread, _ai_analyze_thread, _notify_thread
    try:
        _analyze_thread = threading.Thread(target=analyze_handler, name='_analyze_thread', daemon=True)
        _analyze_thread.start()

        _ai_analyze_thread = threading.Thread(target=ai_analyze_handler, name='_ai_analyze_thread', daemon=True)
        _ai_analyze_thread.start()
    except (Exception,):
        logger.error('Error in notify_handler loop: %s' % traceback.format_exc())

if __name__ == "__main__":
    ...
    # run_analyze()
    # print(get_group_members_simple("0c90c6de-33e3-4431-b5fe-d06378111ef0"))

    # start_time = datetime.strptime("2025-07-09 02:45:00", "%Y-%m-%d %H:%M:%S")
    # end_time = datetime.strptime("2025-07-09 02:47:00", "%Y-%m-%d %H:%M:%S")
    # analyze("0c90c6de-33e3-4431-b5fe-d06378111ef0", start_time, end_time)


