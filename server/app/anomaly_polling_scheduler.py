import asyncio
import queue
import threading
import time
import traceback
from datetime import datetime, timezone, timedelta

from server.app.anomaly_analyze import ai_analyze_anomaly_status, local_analyze
from server.app.anomaly_preprocessor import parse_iso_time
from server.app.database import db
from server.app.jpush_api import send_jpush_notification
from server.app.logger.logger_loader import logger
from server.app.websocket_routes import push_anomaly_analysis_result

_group_id = None
_users_info = None
# 120ç§’çš„é—´éš”
_default_interval_seconds = 120
# ç”¨æˆ·å®šåˆ¶è‡ªå·±çš„æç¤ºé—´éš”æ—¶é—´ï¼Œ(user_id, interval_seconds)
_user_notify_interval_seconds = {}
# ç”¨æˆ·æœ€åä¸€æ¬¡é€šçŸ¥æ—¶é—´
_user_notify_last_time = {}

# æ˜¯å¦åœæ­¢åˆ†æ
_stop_analyze = True

# æ‰§è¡Œåˆ†æä»»åŠ¡çš„çº¿ç¨‹
_analyze_thread = None
_ai_analyze_thread = None

_ai_analyze_q = queue.Queue(1000)
_ai_analyze_result_history = []
_local_analyze_result_history = []

# å¯åŠ¨æ—¶é—´å’Œå¼€å§‹åˆ†ææ—¶é—´ï¼Œç”¨äºåˆ†æå†å²æ•°æ®ï¼Œå¦‚æœ_analyze_start_timeè®¾ç½®æˆå½“å‰æ—¶é—´åˆ™ä»å½“å‰æ—¶é—´å¼€å§‹åˆ†æ
_boot_time = datetime.now(timezone.utc)
_analyze_start_time = datetime.now(timezone.utc)

# _group_id = "cc8f1d29-7a49-4975-95dc-7ac94aefc04b"
# _stop_analyze = False
# _analyze_start_time = parse_iso_time("2025-07-10T07:02:27")
def get_analyze_start_time() -> datetime:
    return _analyze_start_time + (datetime.now(timezone.utc) - _boot_time)

def clear_cache():
    global _group_id, _users_info, _user_notify_interval_seconds, _user_notify_last_time,_ai_analyze_q, _ai_analyze_result_histor, _local_analyze_result_history
    _group_id = None
    _users_info = None
    _user_notify_interval_seconds = {}
    _user_notify_last_time = {}

    _ai_analyze_q = queue.Queue(1000)
    _ai_analyze_result_history = []
    _local_analyze_result_history = []

def feedback_setting(group_id: str, user_id: str, click_type: str, anomaly_analysis_results_id: str = None,
    detail_type: str = None, detail_status: str = None, share_to_user_ids: list = None):
    start_time = time.time()
    logger.info(f"ğŸ–±ï¸ [åé¦ˆç‚¹å‡»] æ”¶åˆ°ç”¨æˆ·{user_id}çš„{click_type}ç‚¹å‡»...")

    # Less\More æ—¶è°ƒæ•´è½®è¯¢å‘¨æœŸ
    global _default_interval_seconds, _user_notify_interval_seconds
    if click_type == "Less":
        old_interval = _user_notify_interval_seconds.get(user_id, _default_interval_seconds)

        if old_interval + 60 <= _default_interval_seconds * 2:
            _user_notify_interval_seconds[user_id] = old_interval + 60

        logger.info(f"ğŸ“Š [åé¦ˆç‚¹å‡»] æ£€æµ‹åˆ°Lessç‚¹å‡»ï¼Œè°ƒæ•´è½®è¯¢é—´éš”: {old_interval}s â†’ {_user_notify_interval_seconds.get(user_id, _default_interval_seconds)}s")
    elif click_type == "More":
        old_interval = _user_notify_interval_seconds.get(user_id, _default_interval_seconds)

        if old_interval - 60 >= _default_interval_seconds:
            _user_notify_interval_seconds[user_id] = old_interval - 60

        logger.info(f"ğŸ“Š [åé¦ˆç‚¹å‡»] æ£€æµ‹åˆ°Moreç‚¹å‡»ï¼Œè°ƒæ•´è½®è¯¢é—´éš”: {old_interval}s â†’ {_user_notify_interval_seconds.get(user_id, _default_interval_seconds)}s")

    click_id = f"{group_id}_{user_id}_{int(datetime.now().timestamp())}"
    feedback_setting = {
        "id": click_id,
        "group_id": group_id,
        "user_id": user_id,
        "click_type": click_type,
        "anomaly_analysis_results_id": anomaly_analysis_results_id,
        "clicked_at": datetime.now(timezone.utc).isoformat(),
        "detail_type": detail_type,
        "detail_status": detail_status,
        "share_to_user_ids": share_to_user_ids,
        "interval_seconds": _user_notify_interval_seconds.get(user_id, _default_interval_seconds),
    }
    db.collection("feedback_clicks").document(click_id).set(feedback_setting)

    logger.info(f"âœ… [åé¦ˆç‚¹å‡»] å®Œæˆï¼è€—æ—¶{(time.time() - start_time):.2f}ç§’")
    return {"message": "åé¦ˆå·²è®°å½•", "feedback_setting": feedback_setting}


def start_analyze(group_id: str):
    clear_cache()

    global _group_id,_stop_analyze
    _stop_analyze = False
    _group_id = group_id

def stop_analyze(group_id: str):
    global _stop_analyze
    _stop_analyze = True

    clear_cache()

def get_local_analyze_result():
    global _local_analyze_result_history
    return _local_analyze_result_history

def get_ai_analyze_result():
    global _ai_analyze_result_history
    return _ai_analyze_result_history

def get_next_notify_ai_analyze_result():
    global _ai_analyze_result_history, _user_notify_last_time, _user_notify_interval_seconds, _default_interval_seconds
    if len(_ai_analyze_result_history) > 0:
        last_ai_analyze_result = _ai_analyze_result_history[-1]
        last_ai_analyze_time = list(last_ai_analyze_result.keys())[0]

        last_ai_analyze_content = last_ai_analyze_result.get(last_ai_analyze_time)

        user_ids = list(last_ai_analyze_content.keys())
        for user_id in user_ids:
            last_notify_time = _user_notify_last_time.get(user_id)
            interval_seconds = _user_notify_interval_seconds.get(user_id, _default_interval_seconds)
            if last_notify_time is None:
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œç”¨AIåˆ†æç»“æœçš„æ—¶é—´ä½œä¸ºä¸‹æ¬¡é€šçŸ¥æ—¶é—´
                next_notify_time = parse_iso_time(last_ai_analyze_time)
            else:
                # ä¸Šä¸€æ¬¡é€šçŸ¥æ—¶é—´+é—´éš”æ—¶é—´ä½œä¸ºä¸‹ä¸€æ¬¡é€šçŸ¥æ—¶é—´
                next_notify_time = last_notify_time + timedelta(seconds=interval_seconds)

            last_ai_analyze_content.get(user_id, {}).update({"next_notify_time": next_notify_time.isoformat()})
    return

def set_notify_time(user_id: str):
    global _user_notify_last_time
    _user_notify_last_time[user_id] = datetime.now(timezone.utc)

def analyze_handler():
    logger.info("ğŸ”„ [å¼‚å¸¸åˆ†æè½®è¯¢] å¯åŠ¨åˆ†æè½®è¯¢çº¿ç¨‹...")
    global _group_id, _stop_analyze, _local_analyze_result_history, _ai_analyze_q

    # 120ç§’çš„åˆ†æé—´éš”
    interval_seconds = 120
    last_analyze_time = None
    while True:
        try:
            if _stop_analyze:
                time.sleep(1)
                continue

            if _group_id is None:
                time.sleep(1)
                logger.error("âŒ [å¼‚å¸¸åˆ†æè½®è¯¢] group_idæœªè®¾ç½®ï¼Œæ— æ³•æ‰§è¡Œåˆ†æã€‚")
                continue


            if last_analyze_time is None:
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œç­‰å¾…interval_secondså†å¼€å§‹
                last_analyze_time = get_analyze_start_time()
                time.sleep(interval_seconds)
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…ã€‚interval_secondsæ‰§è¡Œä¸€æ¬¡åˆ†æï¼Œä¸è¶³æ—¶é—´éœ€è¦ç­‰å¾…
                elapsed = get_analyze_start_time() - last_analyze_time
                if elapsed.total_seconds() < interval_seconds:
                    time.sleep(interval_seconds - elapsed.total_seconds())

            current_time = get_analyze_start_time()

            # æœ¬åœ°æ•°æ®åˆ†æ
            chunk_data_with_local_analyze, local_analyze_result = local_analyze(_group_id, last_analyze_time, current_time)

            # ç¼“å­˜æœ¬åœ°åˆ†æç»“æœ
            if local_analyze_result:
                _local_analyze_result_history.append({current_time.strftime("%Y-%m-%dT%H:%M:%S"): local_analyze_result})
                # åªä¿ç•™æœ€è¿‘20æ¬¡æ‰§è¡Œè®°å½•
                if len(_local_analyze_result_history) > 20:
                    _local_analyze_result_history = _local_analyze_result_history[-20:]


            # å†™å…¥é˜Ÿåˆ—ï¼Œå¼‚æ­¥å¤„ç†AIåˆ†æ
            if chunk_data_with_local_analyze:
                _ai_analyze_q.put((_group_id, chunk_data_with_local_analyze))

            # å–æœ¬æ¬¡åˆ†æçš„å¼€å§‹æ—¶é—´-å³å–æ•°æˆªæ­¢æ—¶é—´ï¼Œä½œä¸ºä¸‹ä¸€æ¬¡åˆ†æçš„èµ·å§‹æ—¶é—´
            last_analyze_time = current_time
        except Exception:
            logger.error('Error in analyze_handler loop: %s' % traceback.format_exc())


def ai_analyze_handler():
    logger.info("ğŸ”„ [AIå¼‚å¸¸åˆ†æ] å¯åŠ¨åˆ†æè½®è¯¢çº¿ç¨‹...")
    global  _stop_analyze, _ai_analyze_q, _ai_analyze_result_history

    while True:
        try:
            time.sleep(1)
            if _stop_analyze:
                continue

            while not _ai_analyze_q.empty():
                group_id, chunk_data_with_local_analyze = _ai_analyze_q.get()

                # è°ƒç”¨AIåˆ†ææ¥å£
                stage_start = time.time()
                result = None
                try:
                    result = asyncio.run(
                        ai_analyze_anomaly_status(group_id, chunk_data_with_local_analyze))
                    if not result:
                        # æ— åˆ†æç»“æœ
                        continue 

                    # ç¼“å­˜åˆ†æç»“æœ
                    end_time_str = chunk_data_with_local_analyze['time_range']['end']
                    _ai_analyze_result_history.append({end_time_str: result})
                    # åªä¿ç•™æœ€è¿‘20æ¬¡æ‰§è¡Œè®°å½•
                    if len(_ai_analyze_result_history) > 20:
                        _ai_analyze_result_history = _ai_analyze_result_history[-20:]
                except Exception as e:
                    logger.error(f"âŒ [AIå¼‚å¸¸åˆ†æ] AIåˆ†æå¼‚å¸¸: {traceback.format_exc()}")
                stage2_duration = time.time() - stage_start
                logger.info(f"ğŸ¤– [AIå¼‚å¸¸åˆ†æ] AIåˆ†æå®Œæˆï¼Œè€—æ—¶{stage2_duration:.2f}ç§’ã€‚ç»“æœï¼š", str(result)[:100])

        except Exception:
            logger.error('Error in ai_analyze_handler loop: %s' % traceback.format_exc())


def run_analyze():
    global _analyze_thread, _ai_analyze_thread, _notify_thread
    try:
        _analyze_thread = threading.Thread(target=analyze_handler, name='_analyze_thread', daemon=True)
        _analyze_thread.start()

        _ai_analyze_thread = threading.Thread(target=ai_analyze_handler, name='_ai_analyze_thread', daemon=True)
        _ai_analyze_thread.start()
    except (Exception,):
        logger.error('Error in notify_handler loop: %s' % traceback.format_exc())

if __name__ == "__main__":
    ...
    # run_analyze()
    # print(get_group_members_simple("0c90c6de-33e3-4431-b5fe-d06378111ef0"))

    # start_time = datetime.strptime("2025-07-09 02:45:00", "%Y-%m-%d %H:%M:%S")
    # end_time = datetime.strptime("2025-07-09 02:47:00", "%Y-%m-%d %H:%M:%S")
    # analyze("0c90c6de-33e3-4431-b5fe-d06378111ef0", start_time, end_time)


