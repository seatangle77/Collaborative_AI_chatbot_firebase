import time
import traceback
from typing import Dict, Any, List

from fastapi import BackgroundTasks
from google.cloud.firestore_v1 import FieldFilter

from server.app.anomaly_analyze import Member, local_analyze
from server.app.anomaly_polling_scheduler import feedback_setting, start_analyze, stop_analyze, \
    get_local_analyze_result, get_ai_analyze_result, get_next_notify_ai_analyze_result
from server.app.database import db
from server.app.logger.logger_loader import logger
from server.app.websocket_routes import push_personal_share_message, push_anomaly_analysis_result

# æ¨¡æ‹Ÿç¼“å­˜ï¼šç”¨äºæš‚å­˜ interval summary ç»“æœ
interval_summary_cache: Dict[str, List[Dict[str, Any]]] = {}

# Firebase Admin SDK å¯¼å…¥ä¸åˆå§‹åŒ–
from firebase_admin import credentials, initialize_app
import firebase_admin

if not len(firebase_admin._apps):
    cred = credentials.Certificate("./server/firebase-key.json")
    initialize_app(cred)

from fastapi import APIRouter, Query
from pydantic import BaseModel
#
from server.app.jpush_api import jpush_personal_share_message, send_jpush_notification
import asyncio
from server.app.websocket_routes import push_stop_task, push_agenda_stage

router = APIRouter()

class IntervalSummaryRequest(BaseModel):
    group_id: str
    round_index: int
    start_time: str
    end_time: str
    members: List[Member]

class GroupPollingRequest(BaseModel):
    group_id: str

class MemberPollingRequest(BaseModel):
    group_id: str
    user_id: str
    interval_minutes: int
    anomaly_analysis_results_id: str = None

class FeedbackClickRequest(BaseModel):
    group_id: str
    user_id: str
    click_type: str  # Less/More/Share
    anomaly_analysis_results_id: str = None
    detail_type: str = None
    detail_status: str = None
    share_to_user_ids: list = None

class PushAiAnalysisRequest(BaseModel):
    push_ji: bool
    device_token: str
    glasses_summary: str
    summary: str
    detail_suggestion: str
    user_id: str
    user_name: str
    push_pc: bool
    ai_analyze_result: dict


# æ›¿æ¢ä¸º POST æ–¹æ³•ï¼Œå‚æ•°ç»“æ„åŒ IntervalSummaryRequestï¼Œé€šè¿‡è¯·æ±‚ä½“æ¥æ”¶
@router.post("/analysis/anomalies")
async def get_anomaly_status(req: IntervalSummaryRequest):
    return get_local_analyze_result()

@router.post("/analysis/get_ai_analyze_result")
async def get_ai_analyze_result(req: IntervalSummaryRequest):
    return get_ai_analyze_result()

@router.post("/analysis/get_next_notify_ai_analyze_result")
async def get_next_notify_ai_analyze_result(req: IntervalSummaryRequest):
    return get_next_notify_ai_analyze_result()

@router.post("/analysis/push_ai_analyze_result")
async def push_ai_analyze_result(req: PushAiAnalysisRequest):
    # æ ¹æ®è¯„åˆ†å†³å®šæ˜¯å¦æ¨é€é€šçŸ¥
    try:
        if req.push_ji:
            # JPush æ¨é€ - ä½¿ç”¨çœ¼é•œç‰ˆæœ¬
            send_jpush_notification(
                alert=req.glasses_summary,  # ç›´æ¥ä½¿ç”¨çœ¼é•œç‰ˆæœ¬ä½œä¸ºæ¨é€å†…å®¹
                registration_id=req.device_token,
                extras={
                    "type": "anomaly",
                    "title": "å¼‚å¸¸æé†’",
                    "body": req.glasses_summary,  # çœ¼é•œç‰ˆæœ¬
                    "summary": req.summary,
                    "suggestion": req.detail_suggestion,
                    "user_id": req.user_id,
                    "user_name": req.user_name
                }
            )
            logger.info(f"âœ… [å¼‚å¸¸åˆ†æ] JPushæ¨é€å®Œæˆï¼Œç”¨æˆ· {req.user_name}({req.user_id}) çœ¼é•œæ˜¾ç¤ºå†…å®¹ï¼š{req.glasses_summary}")
    except Exception as e:
        logger.error(f"âš ï¸ [å¼‚å¸¸åˆ†æ] JPushæ¨é€å¤±è´¥: {traceback.format_exc()}")

    # WebSocket æ¨é€ - å‘PCé¡µé¢æ¨é€å®Œæ•´åˆ†æç»“æœ
    try:
        if req.push_pc:
            await push_anomaly_analysis_result(req.user_id, req.ai_analyze_result)
    except Exception as e:
        logger.error(f"âš ï¸ [å¼‚å¸¸åˆ†æ] WebSocketæ¨é€å¤±è´¥: {traceback.format_exc()}")

    return get_next_notify_ai_analyze_result()

# æ–°å¢ï¼šåªæ‰§è¡Œæœ¬åœ°åˆ†æçš„æ¥å£
@router.post("/analysis/local_anomalies")
async def get_realtime_local_anomaly_status(req: IntervalSummaryRequest):
    """
    åªæ‰§è¡Œæœ¬åœ°åˆ†æï¼Œä¸è°ƒç”¨AIåˆ†æï¼Œç›´æ¥è¿”å›æœ¬åœ°åˆ†æç»“æœ
    """
    try:

        start_time = time.time()
        logger.info(f"ğŸ” [æœ¬åœ°å¼‚å¸¸åˆ†æ] å¼€å§‹åˆ†æ group_id={req.group_id}")
        
        # æœ¬åœ°æ•°æ®åˆ†æ
        chunk_data_with_local_analyze, local_analyze_result = local_analyze(req.group_id, req.start_time, req.end_time, is_save_debug_info=False)

        processing_time = time.time() - start_time
        logger.info(f"ğŸ“Š [æœ¬åœ°å¼‚å¸¸åˆ†æ] åˆ†æå®Œæˆï¼Œè€—æ—¶{processing_time:.2f}ç§’")

        # ç¼“å­˜æœ¬åœ°åˆ†æç»“æœ
        if local_analyze_result:
            return {
                "local_analysis": local_analyze_result,
                "raw_data_summary": {
                    "time_range": chunk_data_with_local_analyze.get('time_range'),
                    "users_count": len(chunk_data_with_local_analyze.get('users', [])),
                    "speech_transcripts_count": len(chunk_data_with_local_analyze.get('raw_tables', {}).get('speech_transcripts', [])),
                    "note_edit_history_count": len(chunk_data_with_local_analyze.get('raw_tables', {}).get('note_edit_history', [])),
                    "pageBehaviorLogs_count": len(chunk_data_with_local_analyze.get('raw_tables', {}).get('pageBehaviorLogs', {}))
                },
                "processing_time": processing_time,
                "analysis_timestamp": time.time()
            }
        else:
            return {
                "local_analysis": None,
                "message": "ç”¨æˆ·æ´»åŠ¨æ•°æ®å¢é‡ä¸º0ï¼Œæ— æ³•è¿›è¡Œåˆ†æ",
                "processing_time": time.time() - start_time
            }
        
    except Exception as e:
        logger.error(f"âŒ [æœ¬åœ°å¼‚å¸¸åˆ†æ] åˆ†æå¤±è´¥: {traceback.format_exc()}")
        return {
            "error": str(e),
            "local_analysis": None,
            "processing_time": time.time() - start_time if 'start_time' in locals() else 0
        }


@router.get("/analysis/anomaly_results_by_user")
async def get_anomaly_results_by_user(
    group_id: str,
    user_id: str = Query(..., description="ç”¨æˆ·ID"),
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(10, ge=1, le=100, description="æ¯é¡µæ¡æ•°ï¼Œæœ€å¤§100")
):

    try:
        # æ³¨æ„ï¼šç”±äºæ•°æ®åº“ä¸­å®é™…æ²¡æœ‰å­˜å‚¨ current_user å­—æ®µï¼Œè¿™é‡Œæš‚æ—¶æŸ¥è¯¢æ‰€æœ‰è®°å½•
        results = db.collection("anomaly_analysis_group_results") \
            .where(filter=FieldFilter("group_id", "==", group_id)) \
            .order_by("created_at", direction="DESCENDING") \
            .stream()

        # è·å–æ€»æ•°
        ai_result_list = [doc.to_dict() for doc in results]
        total = len(ai_result_list)

        # è®¡ç®—åç§»é‡
        offset = (page - 1) * page_size

        # è·å–åˆ†é¡µæ•°æ®
        paginated_docs = ai_result_list[offset:offset + page_size]
        return_list = []
        for doc in paginated_docs:
            raw_response = doc.get("raw_response", {})
            if isinstance(raw_response, dict):
                user_anomaly_result = raw_response.get(user_id, {})
                # æ·»åŠ æ•°æ®åº“è®°å½•çš„ID
                user_anomaly_result["record_id"] = doc.get("id", "")
                user_anomaly_result["start_time"] = doc.get("start_time", "")
                user_anomaly_result["end_time"] = doc.get("end_time", "")
                return_list.append(user_anomaly_result)

        return {
            "results": return_list,
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": (total + page_size - 1) // page_size
        }
        
    except Exception as e:
        logger.info(f"æŸ¥è¯¢å¼‚å¸¸åˆ†æç»“æœå¤±è´¥: {e}")
        # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return {
            "results": [],
            "total": 0,
            "page": page,
            "page_size": page_size,
            "total_pages": 0
        }


@router.post("/analysis/anomaly_polling/start")
async def start_anomaly_polling(req: GroupPollingRequest):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(None, start_analyze, req.group_id)
    await push_agenda_stage(req.group_id, 1)
    return result


@router.post("/analysis/anomaly_polling/stop")
async def stop_anomaly_polling(req: GroupPollingRequest):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(None, stop_analyze, req.group_id)
    await push_stop_task(req.group_id)
    return result

@router.post("/analysis/anomaly_polling/feedback_click")
def feedback_click(req: FeedbackClickRequest, background_tasks: BackgroundTasks):
    result = feedback_setting(req.group_id, req.user_id, req.click_type, req.anomaly_analysis_results_id, req.detail_type, req.detail_status, req.share_to_user_ids)
    
    # Shareæ—¶é€šè¿‡WebSocketæ¨é€
    if req.click_type == "Share" and req.share_to_user_ids:
        logger.info(f"ğŸ“¤ [åé¦ˆç‚¹å‡»] æ£€æµ‹åˆ°Shareç‚¹å‡»ï¼Œå‡†å¤‡æ¨é€æ¶ˆæ¯...")

        for uid in req.share_to_user_ids:
            background_tasks.add_task(
                push_personal_share_message,
                user_id=uid,
                from_user=req.user_id,
                detail_type=req.detail_type,
                detail_status=req.detail_status,
                group_id=req.group_id
            )
            background_tasks.add_task(
                jpush_personal_share_message,
                user_id=uid,
                from_user=req.user_id,
                detail_type=req.detail_type,
                detail_status=req.detail_status,
                group_id=req.group_id
            )

        logger.info(f"ğŸ“¤ [åé¦ˆç‚¹å‡»] å·²æ·»åŠ {len(req.share_to_user_ids)}ä¸ªæ¨é€ä»»åŠ¡")

    return result

