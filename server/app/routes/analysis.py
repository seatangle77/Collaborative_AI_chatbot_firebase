from fastapi import Body
from typing import Dict, Any, List
# æ¨¡æ‹Ÿç¼“å­˜ï¼šç”¨äºæš‚å­˜ interval summary ç»“æœ
interval_summary_cache: Dict[str, List[Dict[str, Any]]] = {}

# Firebase Admin SDK å¯¼å…¥ä¸åˆå§‹åŒ–
from firebase_admin import messaging, credentials, initialize_app
import firebase_admin
import os
if not len(firebase_admin._apps):
    cred = credentials.Certificate("./server/firebase-key.json")
    initialize_app(cred)

from fastapi import APIRouter, Query, HTTPException
import json
from pydantic import BaseModel
#
from app.preprocessor_summary import extract_chunk_data
from app.preprocessor_anomaly import extract_chunk_data_anomaly
from app.analyze_chunk_with_ai import analyze_cognitive, analyze_behavior, analyze_attention
from app.analyze_chunk_with_ai_anomaly import analyze_all_anomalies

router = APIRouter()

class Member(BaseModel):
    id: str
    name: str

class IntervalSummaryRequest(BaseModel):
    group_id: str
    round_index: int
    start_time: str
    end_time: str
    members: List[Member]


# æ›¿æ¢ä¸º POST æ–¹æ³•ï¼Œå‚æ•°ç»“æ„åŒ IntervalSummaryRequestï¼Œé€šè¿‡è¯·æ±‚ä½“æ¥æ”¶
@router.post("/analysis/anomalies")
async def get_anomaly_status(req: IntervalSummaryRequest):
    members = [{"user_id": m.id, "name": m.name} for m in req.members]

    raw_data = extract_chunk_data_anomaly(
        group_id=req.group_id,
        round_index=req.round_index,
        start_time=req.start_time,
        end_time=req.end_time,
        member_list=members
    )
    result = analyze_all_anomalies(raw_data)
    # ä¿å­˜åˆ†æç»“æœä¸ºæ–‡ä»¶
    import uuid
    from datetime import datetime
    os.makedirs("analysis_outputs", exist_ok=True)
    file_name = f"analysis_outputs/anomaly_{uuid.uuid4()}_{datetime.now().strftime('%Y%m%d%H%M%S')}.json"
    with open(file_name, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    # å‘é€æ¨é€é€šçŸ¥åˆ°å®¢æˆ·ç«¯
    from firebase_admin import firestore
    db = firestore.client()

    # å†™æ­» user_id
    target_user_id = "0AlcY0xmqSTWXxAm2f5cT0tNEbJ3"
    user_doc = db.collection("users_info").document(target_user_id).get()
    if user_doc.exists:
        device_token = user_doc.to_dict().get("device_token")
        if device_token:
            message = messaging.Message(
                notification=messaging.Notification(
                    title="ğŸ“¡ å¼‚å¸¸åˆ†æå®Œæˆ",
                    body="æ–°çš„å¼‚å¸¸æ£€æµ‹ç»“æœå·²ç”Ÿæˆï¼Œç‚¹å‡»æŸ¥çœ‹åˆ†æè¯¦æƒ…ã€‚"
                ),
                token=device_token
            )
            try:
                response = messaging.send(message)
                print("âœ… æ¨é€æˆåŠŸ:", response)
            except Exception as e:
                print("âŒ æ¨é€å¤±è´¥:", e)
        else:
            print("âš ï¸ ç”¨æˆ·æœªè®¾ç½® device_token")
    else:
        print("âŒ ç”¨æˆ·ä¸å­˜åœ¨:", target_user_id)

    return result


@router.post("/analysis/interval_summary")
async def interval_summary(req: IntervalSummaryRequest):
    """
    æ¯5åˆ†é’Ÿè‡ªåŠ¨åˆ†æä¸€æ¬¡ï¼Œå°†æ®µè½åˆ†æç»“æœæš‚å­˜ï¼ˆæ¨¡æ‹Ÿç¼“å­˜ï¼‰ã€‚
    """
    import uuid
    from datetime import datetime
    import os

    members = [{"user_id": m.id, "name": m.name} for m in req.members]

    # é€šè¿‡ extract_chunk_data è·å– chunk æ•°æ®
    chunk_data = extract_chunk_data(
        group_id=req.group_id,
        round_index=req.round_index,
        start_time=req.start_time,
        end_time=req.end_time,
        member_list=members
    )
    #print("ğŸ§ª chunk_data result:", chunk_data)

    cog_result = analyze_cognitive(chunk_data)
    beh_result = analyze_behavior(chunk_data)
    attn_result = analyze_attention(chunk_data)

    os.makedirs("analysis_outputs", exist_ok=True)
    result = {
        "cognitive": cog_result,
        "behavior": beh_result,
        "attention": attn_result
    }
    file_name = f"analysis_outputs/interval_{uuid.uuid4()}_{datetime.now().strftime('%Y%m%d%H%M%S')}.json"
    with open(file_name, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    return result


@router.get("/analysis/round_summary_combined")
async def round_summary_combined(
    group_id: str = Query(...),
    round_index: int = Query(...),
    start_time: str = Query(...),
    end_time: str = Query(...)
):
    """
    å½“å‰è½®ç»“æŸåæ‰‹åŠ¨è§¦å‘ï¼Œå°†æ‰€æœ‰ interval summary æ±‡æ€»æˆå®Œæ•´ä¸€è½®æ€»ç»“ã€‚
    """
    cache_key = f"{group_id}:{round_index}"
    interval_chunks = interval_summary_cache.get(cache_key, [])
    # æŒ‰ç”¨æˆ·åˆ†ç»„ï¼Œæ”¶é›†æ‰€æœ‰chunkçš„summary
    user_chunks = {}
    for chunk in interval_chunks:
        uid = chunk["user_id"]
        if uid not in user_chunks:
            user_chunks[uid] = []
        user_chunks[uid].append(chunk["summary"])

    members = []
    for user_id, summaries in user_chunks.items():
        # å¯ä»¥è¿›ä¸€æ­¥åˆå¹¶æ¯ä¸ªsummaryçš„levelï¼ˆå–ä¼—æ•°æˆ–å¹³å‡ç­‰ï¼‰
        behavioral_levels = [s.get("behavioral_level") for s in summaries]
        cognitive_levels = [s.get("cognitive_level") for s in summaries]
        attention_levels = [s.get("shared_attention") for s in summaries]

        def most_common_level(levels):
            return max(set(levels), key=levels.count) if levels else "æœªçŸ¥"

        # æ±‡æ€»
        member_summary = {
            "time_range": {
                "start": start_time,
                "end": end_time
            },
            "user_id": user_id,
            "round": round_index,
            "behavioral_level": most_common_level(behavioral_levels),
            "cognitive_level": most_common_level(cognitive_levels),
            "shared_attention": most_common_level(attention_levels),
            "suggestions": [
                "è¯·å°è¯•æé«˜è®¤çŸ¥äº’åŠ¨æ°´å¹³",
                "æ˜¯å¦å¯ä»¥è¿›ä¸€æ­¥èšç„¦ç›¸ä¼¼é¡µé¢"
            ],
            "anomalies": []
        }
        members.append(member_summary)

    # æ±‡æ€» group
    all_behaviors = [m["behavioral_level"] for m in members]
    all_cognition = [m["cognitive_level"] for m in members]
    all_attention = [m["shared_attention"] for m in members]
    def most_common_level(levels):
        return max(set(levels), key=levels.count) if levels else "æœªçŸ¥"
    group_summary = {
        "time_range": {
            "start": start_time,
            "end": end_time
        },
        "user_id": "group",
        "round": round_index,
        "behavioral_level": most_common_level(all_behaviors),
        "cognitive_level": most_common_level(all_cognition),
        "shared_attention": most_common_level(all_attention),
        "suggestions": [
            "è¯·å°è¯•æé«˜è®¤çŸ¥äº’åŠ¨æ°´å¹³",
            "æ˜¯å¦å¯ä»¥è¿›ä¸€æ­¥èšç„¦ç›¸ä¼¼é¡µé¢"
        ]
    }

    return {
        "group_summary": group_summary,
        "members": members
    }